{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для \"Викишоп\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Требуется обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ход работы:**\n",
    "1. Загрузка и подготовка данных\n",
    "2. Обучение моделей\n",
    "3. Вывод\n",
    "\n",
    "**Описание данных:**\n",
    "- Данные находятся в файле `/datasets/toxic_comments.csv`.\n",
    "- Столбец `text` содержит текст комментария, столбец `toxic` - целевой признак.\n",
    "\n",
    "**Цель:**\n",
    "- Построить модель со значением метрики качества F1 не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и проверка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chernyse\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "# Импорты, настройки\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Константы\n",
    "SEED = 777 # в деле со случайностями важна удача"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1                1  D'aww! He matches this background colour I'm s...      0\n",
       "2                2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3                3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4                4  You, sir, are my hero. Any chance you remember...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  \":::::And for the second time of asking, when ...      0\n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Промежуточный вывод:**\n",
    "\n",
    "Дубликатов нет, данные выглядят корректно. \n",
    "\n",
    "В файле имеется столбец с порядковыми номерами записей. Удалим его, так как он неинформативен.\n",
    "\n",
    "Также обнаружили, что целевой признак имеет дисбаланс. Следует учесть это при разбивке объектов по выборкам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем текст. Предварительно создадим копию имеющегося датафрейма, который изменим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для лемматизации английских текстов воспользуемся средствами библиотеки spaCy.\n",
    "\n",
    "Протестируем его пригодность на случайном английском тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a plague o ' both your house ! they have make worm ' meat of I : I have it , and soundly too : your house !\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "example = \"A plague o' both your houses! They have made worms' meat of me: I have it, And soundly too: your houses!\"\n",
    "\n",
    "doc = nlp(example)\n",
    "\n",
    "\" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат приемлем. Напишем функцию для обработки имеющегося датасета, а заодно функцию для очистки текста от ненужных символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lemma(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    subed = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    subed = subed.split()\n",
    "    subed = \" \".join(subed)\n",
    "    return subed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизированный текст сохраним в отдельном столбце для последующего сравнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c728020e44742269faddccf05943a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159292.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 49min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['lemm_text'] = data['text'].progress_apply(to_lemma).apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8491</th>\n",
       "      <td>Personally I think the boxes are a better form...</td>\n",
       "      <td>0</td>\n",
       "      <td>personally I think the box be a well format an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89770</th>\n",
       "      <td>Then I guess you'll have to deal with her.</td>\n",
       "      <td>0</td>\n",
       "      <td>then I guess you will have to deal with she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123636</th>\n",
       "      <td>I'm extremely inclined to revert User:QuackGur...</td>\n",
       "      <td>0</td>\n",
       "      <td>I be extremely inclined to revert User QuackGu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83925</th>\n",
       "      <td>\"\\n\\nWhat do you think this means?\\nI wonder w...</td>\n",
       "      <td>0</td>\n",
       "      <td>what do you think this mean I wonder what this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138867</th>\n",
       "      <td>BTW, as you've now updated your views at the b...</td>\n",
       "      <td>0</td>\n",
       "      <td>btw as you ve now update your view at the bott...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76651</th>\n",
       "      <td>You are wrong on all points. And, you may be g...</td>\n",
       "      <td>0</td>\n",
       "      <td>you be wrong on all point and you may be guilt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>\"\\n\\nThanks.  That's three of us now, and coun...</td>\n",
       "      <td>0</td>\n",
       "      <td>thank that be three of we now and count but yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63445</th>\n",
       "      <td>I KNOW IT'S ENGLAND BECAUSE IT SAYS UTC \\n\\nIN...</td>\n",
       "      <td>1</td>\n",
       "      <td>I know it be ENGLAND because it say UTC in FAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120797</th>\n",
       "      <td>All fine! \\n\\nI honestly only had to put one c...</td>\n",
       "      <td>0</td>\n",
       "      <td>all fine I honestly only have to put one comma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74257</th>\n",
       "      <td>A message for you \\n\\nFuck you!\\n\\nGAYFullbust...</td>\n",
       "      <td>1</td>\n",
       "      <td>a message for you fuck you GAYFullbuster Put t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "8491    Personally I think the boxes are a better form...      0   \n",
       "89770          Then I guess you'll have to deal with her.      0   \n",
       "123636  I'm extremely inclined to revert User:QuackGur...      0   \n",
       "83925   \"\\n\\nWhat do you think this means?\\nI wonder w...      0   \n",
       "138867  BTW, as you've now updated your views at the b...      0   \n",
       "76651   You are wrong on all points. And, you may be g...      0   \n",
       "3235    \"\\n\\nThanks.  That's three of us now, and coun...      0   \n",
       "63445   I KNOW IT'S ENGLAND BECAUSE IT SAYS UTC \\n\\nIN...      1   \n",
       "120797  All fine! \\n\\nI honestly only had to put one c...      0   \n",
       "74257   A message for you \\n\\nFuck you!\\n\\nGAYFullbust...      1   \n",
       "\n",
       "                                                lemm_text  \n",
       "8491    personally I think the box be a well format an...  \n",
       "89770         then I guess you will have to deal with she  \n",
       "123636  I be extremely inclined to revert User QuackGu...  \n",
       "83925   what do you think this mean I wonder what this...  \n",
       "138867  btw as you ve now update your view at the bott...  \n",
       "76651   you be wrong on all point and you may be guilt...  \n",
       "3235    thank that be three of we now and count but yo...  \n",
       "63445   I know it be ENGLAND because it say UTC in FAC...  \n",
       "120797  all fine I honestly only have to put one comma...  \n",
       "74257   a message for you fuck you GAYFullbuster Put t...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверяем случайные строки, ищем несоответствия\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обнаружили, что заглавные буквы изменяются только если она первая в строке. Переведём все буквы в нижний регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126827</th>\n",
       "      <td>Hello, I am a student at the school whos IP ad...</td>\n",
       "      <td>0</td>\n",
       "      <td>hello i be a student at the school who s ip ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126443</th>\n",
       "      <td>Comments about C.Fred==\\n\\nYour edits make no ...</td>\n",
       "      <td>0</td>\n",
       "      <td>comment about c fred your edit make no sense y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620</th>\n",
       "      <td>That is completely unencyclopedic content whic...</td>\n",
       "      <td>0</td>\n",
       "      <td>that be completely unencyclopedic content whic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "126827  Hello, I am a student at the school whos IP ad...      0   \n",
       "126443  Comments about C.Fred==\\n\\nYour edits make no ...      0   \n",
       "4620    That is completely unencyclopedic content whic...      0   \n",
       "\n",
       "                                                lemm_text  \n",
       "126827  hello i be a student at the school who s ip ad...  \n",
       "126443  comment about c fred your edit make no sense y...  \n",
       "4620    that be completely unencyclopedic content whic...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.lemm_text = data.lemm_text.str.lower()\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат приемлем. Столбец `text` удаляем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('text', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка признаков, векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как заказчику необходима работа с неизвестными текстами, для корректного построения моделей разделим заранее выборку на обучающую и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.toxic\n",
    "features = data.drop(['toxic'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборку, где тестовая выборка будет составлять 25%. Также применим стратификацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, stratify=target, test_size=0.25, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898392\n",
       "1    0.101608\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898375\n",
       "1    0.101625\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем результат разделения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119469, 1)\n",
      "(39823, 1)\n",
      "(119469,)\n",
      "(39823,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим корпусы для каждой выборки. Так как наша цель - создать модели для английских текстов и исходные данные заявлены как написанные латиницей тексты, кодировку оставим имеющуюся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Корпус тренировочной выборки\n",
    "corpus_train = features_train['lemm_text']\n",
    "\n",
    "#Корпус тестовой выборки для будущих тестов\n",
    "corpus_test = features_test['lemm_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим стоп-слова и ознакомимся с их списком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chernyse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как нам неизвестны будущие тексты (в данном случае - тестовые), функцию fit() применим только для обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = count_tf_idf.fit_transform(corpus_train)\n",
    "features_test = count_tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119469, 132891)\n",
      "(39823, 132891)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_0, features_temp, target_train_0, target_temp = train_test_split(\n",
    "    features, target, stratify=target, test_size=0.4, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test_0, features_valid_0, target_test_0, target_valid_0 = train_test_split(\n",
    "    features_temp, target_temp, stratify=target_temp, test_size=0.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95575, 1)\n",
      "(31859, 1)\n",
      "(31858, 1)\n",
      "(95575,)\n",
      "(31859,)\n",
      "(31858,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train_0.shape)\n",
    "print(features_valid_0.shape)\n",
    "print(features_test_0.shape)\n",
    "print(target_train_0.shape)\n",
    "print(target_valid_0.shape)\n",
    "print(target_test_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train_0 = features_train_0['lemm_text']\n",
    "corpus_valid_0 = features_valid_0['lemm_text']\n",
    "corpus_test_0 = features_test_0['lemm_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_0 = count_tf_idf.fit_transform(corpus_train_0)\n",
    "features_valid_0 = count_tf_idf.transform(corpus_valid_0)\n",
    "features_test_0 = count_tf_idf.transform(corpus_test_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдём к построению моделей.\n",
    "\n",
    "За метрики качества возьмём F1-меру, а также построим матрицу ошибок для детального понимания поведения моделей и последующих рекомендаций заказчику. Подготовим функцию для вывода метрик качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_me_quality_please(targets, predictions):\n",
    "    print(\"Точность предсказаний:\", round(accuracy_score(targets, predictions), 3))\n",
    "    print('-'*25)\n",
    "    print(\"F1-мера\", round(f1_score(targets, predictions), 3))\n",
    "    print('-'*25)\n",
    "    print(\"Матрица ошибок:\\n\", confusion_matrix(targets, predictions, normalize='true')) #т.к. будем сравнимать матрицы разного объёма, нормализуем для наглядности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(max_iter=300, class_weight='balanced', random_state=SEED, C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', max_iter=300,\n",
       "                   random_state=777)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr.fit(features_train_0, target_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lr_valid = model_lr.predict(features_valid_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность предсказаний: 0.949\n",
      "-------------------------\n",
      "F1-мера 0.762\n",
      "-------------------------\n",
      "Матрица ошибок:\n",
      " [[0.96488715 0.03511285]\n",
      " [0.1940068  0.8059932 ]]\n"
     ]
    }
   ],
   "source": [
    "show_me_quality_please(target_valid_0, prediction_lr_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-мера на валидационной выборке составляет 0.762. Сравним с другими моделями для последующего выбора для испытаний на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Оставил, чтобы было понятно, что это тут было.\n",
    "\n",
    "#prediction_lr_test = model_lr.predict(features_test)\n",
    "#show_me_quality_please(target_test, prediction_lr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-мера достаточна для решения задачи.\n",
    "\n",
    "Матрица ошибок показывает, что на тестовой выборке в >4 раз увеличилось количество ложноотрицательных ответов. Можем сделать предположение: люди используют нецензурные выражения на эмоциях, когда не обращают внимание на грамматику, совершая ошибки и создавая новые ругательные слова и n-граммы. Поэтому такие выражения для алгоритма являются уникальными и неизвестными.\n",
    "\n",
    "Рассмотрим модели, построенные с использованием других алгоритмов, обратив внимание на распределение значений в матрице ошибок:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберём параметры с использованием GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "#model_rfc = RandomForestClassifier(random_state=SEED)\n",
    "#params_rfc = {'n_estimators': [50, 100],\n",
    "#             'max_depth': [100]}\n",
    "#grid_rfc = GridSearchCV(model_rfc, params_rfc, cv=5, n_jobs=-1)\n",
    "#grid_rfc.fit(features_train, target_train)\n",
    "#print(grid_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rfc = Pipeline([\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('rfc', RandomForestClassifier(random_state=SEED))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая F1-мера: 0.31818794609936213\n",
      "Лучшие параметры: {'rfc__max_depth': 100, 'rfc__n_estimators': 3}\n"
     ]
    }
   ],
   "source": [
    "pipeline_rfc_params = {'rfc__n_estimators': [3, 5],\n",
    "                      'rfc__max_depth': [100]}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_rfc, pipeline_rfc_params, n_jobs=-1, verbose=1, scoring='f1')\n",
    "\n",
    "grid_search.fit(features_train_0, target_train_0)\n",
    "\n",
    "print('Лучшая F1-мера:', grid_search.best_score_)\n",
    "print('Лучшие параметры:', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность предсказаний: 0.933\n",
      "-------------------------\n",
      "F1-мера 0.52\n",
      "-------------------------\n",
      "Матрица ошибок:\n",
      " [[0.9988121  0.0011879 ]\n",
      " [0.64535063 0.35464937]]\n"
     ]
    }
   ],
   "source": [
    "model_rfc_0 = RandomForestClassifier(random_state=SEED, n_estimators=3, max_depth=100)\n",
    "model_rfc_0.fit(features_valid_0, target_valid_0)\n",
    "prediction_rfc_valid_0 = model_rfc_0.predict(features_valid_0)\n",
    "show_me_quality_please(target_valid_0, prediction_rfc_valid_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Оставил, чтобы было понятно, что это тут было.\n",
    "\n",
    "#prediction_rfc_test = model_rfc.predict(features_test)\n",
    "#show_me_quality_please(target_test, prediction_rfc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели случайного леса слишком низкое для какой-либо работы. Также эта модель занимает слишком много памяти, что делает её ещё более неэффективной.\n",
    "\n",
    "На матрице ошибок видим, что значение ложноположительных ответов слишком велико, по сравнению с моделью логистической регрессии.\n",
    "\n",
    "**UPD** F1-мера на валидационной выборке недостаточна для дальнейшей работы с этой моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model_cbc = CatBoostClassifier(random_state=SEED)\n",
    "#params_cbc = {'depth': [8],\n",
    "#             'learning_rate': [0.3]}\n",
    "\n",
    "#grid_cbc = model_cbc.grid_search(params_cbc, X=features_train, y=target_train)\n",
    "#grid_cbc['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Время исполнения блока - 24 минуты\n",
    "\n",
    "#model_cbc = CatBoostClassifier(random_state=SEED, iterations=100, depth=8, custom_metric='F1')\n",
    "#model_cbc.fit(features_train, target_train)\n",
    "#prediction_cbc_train = model_cbc.predict(features_train)\n",
    "#show_me_quality_please(target_train, prediction_cbc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Копирую вывод предыдущего блока*\n",
    "\n",
    "Точность предсказаний: 0.965\n",
    "\n",
    "F1-мера 0.801\n",
    "\n",
    "Матрица ошибок:\n",
    "\n",
    " [[0.99460542 0.00539458]\n",
    " \n",
    " [0.30068375 0.69931625]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-мера достигает 0.8. Протестируем модель на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Закомментировал, чтобы не выводилась ошибка\n",
    "\n",
    "#prediction_cbc_test = model_cbc.predict(features_test)\n",
    "#show_me_quality_please(target_test, prediction_cbc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Копирую вывод предыдущего блока*\n",
    "\n",
    "Точность предсказаний: 0.956\n",
    "\n",
    "F1-мера 0.752\n",
    "\n",
    "Матрица ошибок:\n",
    "\n",
    "[[0.9910275  0.0089725 ]\n",
    "\n",
    "[0.34964171 0.65035829]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель, построенная по алгоритмам CatBoost, имеет слишком долгое время обучения, не отражая это в повышенном качестве. Несмотря на то, что на тестовой выборке модель достигла F1-меры 0.752, количество ложноположительных ответов достигает 30%, что недопустимо для качественной работы и хуже модели логистической регрессии. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.315861\n",
      "0:\tlearn: 0.4272870\ttotal: 23.7s\tremaining: 1h 18m 36s\n",
      "1:\tlearn: 0.3157364\ttotal: 45.2s\tremaining: 1h 14m 35s\n",
      "2:\tlearn: 0.2644874\ttotal: 1m 2s\tremaining: 1h 8m 45s\n",
      "3:\tlearn: 0.2383811\ttotal: 1m 16s\tremaining: 1h 2m 7s\n",
      "4:\tlearn: 0.2223109\ttotal: 1m 24s\tremaining: 54m 56s\n",
      "5:\tlearn: 0.2131348\ttotal: 1m 32s\tremaining: 49m 46s\n",
      "6:\tlearn: 0.2053870\ttotal: 1m 41s\tremaining: 46m 26s\n",
      "7:\tlearn: 0.1999146\ttotal: 1m 48s\tremaining: 43m 32s\n",
      "8:\tlearn: 0.1942664\ttotal: 1m 56s\tremaining: 41m 15s\n",
      "9:\tlearn: 0.1905505\ttotal: 2m 4s\tremaining: 39m 23s\n",
      "10:\tlearn: 0.1870393\ttotal: 2m 11s\tremaining: 37m 47s\n",
      "11:\tlearn: 0.1841779\ttotal: 2m 19s\tremaining: 36m 25s\n",
      "12:\tlearn: 0.1816045\ttotal: 2m 27s\tremaining: 35m 17s\n",
      "13:\tlearn: 0.1786934\ttotal: 2m 39s\tremaining: 35m 16s\n",
      "14:\tlearn: 0.1761508\ttotal: 3m 1s\tremaining: 37m 14s\n",
      "15:\tlearn: 0.1736454\ttotal: 3m 18s\tremaining: 38m 5s\n",
      "16:\tlearn: 0.1714593\ttotal: 3m 30s\tremaining: 37m 41s\n",
      "17:\tlearn: 0.1697909\ttotal: 3m 55s\tremaining: 39m 45s\n",
      "18:\tlearn: 0.1684037\ttotal: 4m 12s\tremaining: 40m 8s\n",
      "19:\tlearn: 0.1665914\ttotal: 4m 25s\tremaining: 39m 52s\n",
      "20:\tlearn: 0.1653048\ttotal: 4m 36s\tremaining: 39m 17s\n",
      "21:\tlearn: 0.1638619\ttotal: 4m 47s\tremaining: 38m 44s\n",
      "22:\tlearn: 0.1623147\ttotal: 4m 55s\tremaining: 37m 56s\n",
      "23:\tlearn: 0.1609938\ttotal: 5m 3s\tremaining: 37m 6s\n",
      "24:\tlearn: 0.1599990\ttotal: 5m 14s\tremaining: 36m 44s\n",
      "25:\tlearn: 0.1584079\ttotal: 5m 27s\tremaining: 36m 34s\n",
      "26:\tlearn: 0.1568717\ttotal: 5m 41s\tremaining: 36m 27s\n",
      "27:\tlearn: 0.1558969\ttotal: 5m 56s\tremaining: 36m 27s\n",
      "28:\tlearn: 0.1548031\ttotal: 6m 7s\tremaining: 36m 6s\n",
      "29:\tlearn: 0.1537553\ttotal: 6m 18s\tremaining: 35m 45s\n",
      "30:\tlearn: 0.1525549\ttotal: 6m 28s\tremaining: 35m 19s\n",
      "31:\tlearn: 0.1517150\ttotal: 6m 37s\tremaining: 34m 49s\n",
      "32:\tlearn: 0.1506116\ttotal: 6m 46s\tremaining: 34m 16s\n",
      "33:\tlearn: 0.1498845\ttotal: 6m 56s\tremaining: 33m 51s\n",
      "34:\tlearn: 0.1489911\ttotal: 7m 5s\tremaining: 33m 27s\n",
      "35:\tlearn: 0.1483235\ttotal: 7m 13s\tremaining: 32m 56s\n",
      "36:\tlearn: 0.1475143\ttotal: 7m 22s\tremaining: 32m 30s\n",
      "37:\tlearn: 0.1467870\ttotal: 7m 31s\tremaining: 32m 2s\n",
      "38:\tlearn: 0.1460004\ttotal: 7m 40s\tremaining: 31m 42s\n",
      "39:\tlearn: 0.1452478\ttotal: 7m 50s\tremaining: 31m 22s\n",
      "40:\tlearn: 0.1441143\ttotal: 8m 4s\tremaining: 31m 20s\n",
      "41:\tlearn: 0.1434624\ttotal: 8m 16s\tremaining: 31m 9s\n",
      "42:\tlearn: 0.1428290\ttotal: 8m 27s\tremaining: 30m 51s\n",
      "43:\tlearn: 0.1423302\ttotal: 8m 48s\tremaining: 31m 14s\n",
      "44:\tlearn: 0.1413904\ttotal: 9m 12s\tremaining: 31m 43s\n",
      "45:\tlearn: 0.1404484\ttotal: 9m 43s\tremaining: 32m 32s\n",
      "46:\tlearn: 0.1397980\ttotal: 10m 3s\tremaining: 32m 46s\n",
      "47:\tlearn: 0.1393648\ttotal: 10m 29s\tremaining: 33m 13s\n",
      "48:\tlearn: 0.1389720\ttotal: 10m 52s\tremaining: 33m 29s\n",
      "49:\tlearn: 0.1383434\ttotal: 11m 10s\tremaining: 33m 31s\n",
      "50:\tlearn: 0.1376508\ttotal: 11m 25s\tremaining: 33m 23s\n",
      "51:\tlearn: 0.1368763\ttotal: 11m 37s\tremaining: 33m 5s\n",
      "52:\tlearn: 0.1362953\ttotal: 11m 50s\tremaining: 32m 51s\n",
      "53:\tlearn: 0.1356963\ttotal: 12m 1s\tremaining: 32m 31s\n",
      "54:\tlearn: 0.1348689\ttotal: 12m 13s\tremaining: 32m 13s\n",
      "55:\tlearn: 0.1343048\ttotal: 12m 22s\tremaining: 31m 49s\n",
      "56:\tlearn: 0.1334874\ttotal: 12m 32s\tremaining: 31m 28s\n",
      "57:\tlearn: 0.1329161\ttotal: 12m 42s\tremaining: 31m 7s\n",
      "58:\tlearn: 0.1323490\ttotal: 12m 51s\tremaining: 30m 44s\n",
      "59:\tlearn: 0.1317785\ttotal: 13m 4s\tremaining: 30m 30s\n",
      "60:\tlearn: 0.1312773\ttotal: 13m 16s\tremaining: 30m 13s\n",
      "61:\tlearn: 0.1309196\ttotal: 13m 27s\tremaining: 29m 56s\n",
      "62:\tlearn: 0.1306060\ttotal: 13m 41s\tremaining: 29m 46s\n",
      "63:\tlearn: 0.1301169\ttotal: 13m 52s\tremaining: 29m 29s\n",
      "64:\tlearn: 0.1294151\ttotal: 14m 5s\tremaining: 29m 15s\n",
      "65:\tlearn: 0.1290526\ttotal: 14m 19s\tremaining: 29m 5s\n",
      "66:\tlearn: 0.1286210\ttotal: 14m 29s\tremaining: 28m 45s\n",
      "67:\tlearn: 0.1283773\ttotal: 14m 42s\tremaining: 28m 32s\n",
      "68:\tlearn: 0.1280824\ttotal: 15m 2s\tremaining: 28m 33s\n",
      "69:\tlearn: 0.1278511\ttotal: 15m 17s\tremaining: 28m 23s\n",
      "70:\tlearn: 0.1273338\ttotal: 15m 40s\tremaining: 28m 28s\n",
      "71:\tlearn: 0.1270897\ttotal: 15m 58s\tremaining: 28m 23s\n",
      "72:\tlearn: 0.1265482\ttotal: 16m 18s\tremaining: 28m 23s\n",
      "73:\tlearn: 0.1261186\ttotal: 16m 40s\tremaining: 28m 22s\n",
      "74:\tlearn: 0.1254770\ttotal: 16m 52s\tremaining: 28m 7s\n",
      "75:\tlearn: 0.1252478\ttotal: 17m 3s\tremaining: 27m 50s\n",
      "76:\tlearn: 0.1245073\ttotal: 17m 12s\tremaining: 27m 29s\n",
      "77:\tlearn: 0.1240063\ttotal: 17m 23s\tremaining: 27m 12s\n",
      "78:\tlearn: 0.1237997\ttotal: 17m 33s\tremaining: 26m 52s\n",
      "79:\tlearn: 0.1234840\ttotal: 17m 42s\tremaining: 26m 33s\n",
      "80:\tlearn: 0.1230199\ttotal: 17m 53s\tremaining: 26m 16s\n",
      "81:\tlearn: 0.1224788\ttotal: 18m 11s\tremaining: 26m 11s\n",
      "82:\tlearn: 0.1222560\ttotal: 18m 20s\tremaining: 25m 51s\n",
      "83:\tlearn: 0.1218107\ttotal: 18m 33s\tremaining: 25m 37s\n",
      "84:\tlearn: 0.1216124\ttotal: 18m 41s\tremaining: 25m 16s\n",
      "85:\tlearn: 0.1211155\ttotal: 18m 57s\tremaining: 25m 7s\n",
      "86:\tlearn: 0.1209182\ttotal: 19m 6s\tremaining: 24m 48s\n",
      "87:\tlearn: 0.1204622\ttotal: 19m 15s\tremaining: 24m 31s\n",
      "88:\tlearn: 0.1202582\ttotal: 19m 25s\tremaining: 24m 13s\n",
      "89:\tlearn: 0.1198600\ttotal: 19m 33s\tremaining: 23m 54s\n",
      "90:\tlearn: 0.1196147\ttotal: 19m 42s\tremaining: 23m 36s\n",
      "91:\tlearn: 0.1191000\ttotal: 19m 52s\tremaining: 23m 19s\n",
      "92:\tlearn: 0.1189148\ttotal: 20m 3s\tremaining: 23m 5s\n",
      "93:\tlearn: 0.1187393\ttotal: 20m 12s\tremaining: 22m 47s\n",
      "94:\tlearn: 0.1183733\ttotal: 20m 21s\tremaining: 22m 29s\n",
      "95:\tlearn: 0.1178998\ttotal: 20m 29s\tremaining: 22m 12s\n",
      "96:\tlearn: 0.1177222\ttotal: 20m 43s\tremaining: 22m\n",
      "97:\tlearn: 0.1175455\ttotal: 20m 53s\tremaining: 21m 44s\n",
      "98:\tlearn: 0.1170998\ttotal: 21m 1s\tremaining: 21m 27s\n",
      "99:\tlearn: 0.1169348\ttotal: 21m 9s\tremaining: 21m 9s\n",
      "100:\tlearn: 0.1166049\ttotal: 21m 19s\tremaining: 20m 53s\n",
      "101:\tlearn: 0.1161799\ttotal: 21m 27s\tremaining: 20m 37s\n",
      "102:\tlearn: 0.1160051\ttotal: 21m 36s\tremaining: 20m 21s\n",
      "103:\tlearn: 0.1158542\ttotal: 21m 45s\tremaining: 20m 5s\n",
      "104:\tlearn: 0.1156999\ttotal: 21m 54s\tremaining: 19m 49s\n",
      "105:\tlearn: 0.1155599\ttotal: 22m 5s\tremaining: 19m 35s\n",
      "106:\tlearn: 0.1151663\ttotal: 22m 18s\tremaining: 19m 23s\n",
      "107:\tlearn: 0.1149950\ttotal: 22m 28s\tremaining: 19m 8s\n",
      "108:\tlearn: 0.1148067\ttotal: 22m 38s\tremaining: 18m 54s\n",
      "109:\tlearn: 0.1146049\ttotal: 22m 50s\tremaining: 18m 41s\n",
      "110:\tlearn: 0.1142949\ttotal: 22m 59s\tremaining: 18m 26s\n",
      "111:\tlearn: 0.1141603\ttotal: 23m 12s\tremaining: 18m 14s\n",
      "112:\tlearn: 0.1138063\ttotal: 23m 21s\tremaining: 17m 59s\n",
      "113:\tlearn: 0.1133901\ttotal: 23m 31s\tremaining: 17m 44s\n",
      "114:\tlearn: 0.1131160\ttotal: 23m 40s\tremaining: 17m 29s\n",
      "115:\tlearn: 0.1128376\ttotal: 23m 48s\tremaining: 17m 14s\n",
      "116:\tlearn: 0.1127082\ttotal: 23m 57s\tremaining: 16m 59s\n",
      "117:\tlearn: 0.1125377\ttotal: 24m 5s\tremaining: 16m 44s\n",
      "118:\tlearn: 0.1124085\ttotal: 24m 15s\tremaining: 16m 30s\n",
      "119:\tlearn: 0.1122859\ttotal: 24m 23s\tremaining: 16m 15s\n",
      "120:\tlearn: 0.1119135\ttotal: 24m 31s\tremaining: 16m 1s\n",
      "121:\tlearn: 0.1116996\ttotal: 24m 39s\tremaining: 15m 46s\n",
      "122:\tlearn: 0.1113854\ttotal: 24m 48s\tremaining: 15m 31s\n",
      "123:\tlearn: 0.1110350\ttotal: 24m 58s\tremaining: 15m 18s\n",
      "124:\tlearn: 0.1108353\ttotal: 25m 7s\tremaining: 15m 4s\n",
      "125:\tlearn: 0.1105123\ttotal: 25m 16s\tremaining: 14m 50s\n",
      "126:\tlearn: 0.1103930\ttotal: 25m 26s\tremaining: 14m 37s\n",
      "127:\tlearn: 0.1102747\ttotal: 25m 34s\tremaining: 14m 23s\n",
      "128:\tlearn: 0.1099307\ttotal: 25m 43s\tremaining: 14m 9s\n",
      "129:\tlearn: 0.1095139\ttotal: 25m 54s\tremaining: 13m 57s\n",
      "130:\tlearn: 0.1093856\ttotal: 26m 5s\tremaining: 13m 44s\n",
      "131:\tlearn: 0.1092288\ttotal: 26m 15s\tremaining: 13m 31s\n",
      "132:\tlearn: 0.1087088\ttotal: 26m 26s\tremaining: 13m 19s\n",
      "133:\tlearn: 0.1085228\ttotal: 26m 36s\tremaining: 13m 6s\n",
      "134:\tlearn: 0.1081755\ttotal: 26m 45s\tremaining: 12m 52s\n",
      "135:\tlearn: 0.1080676\ttotal: 26m 54s\tremaining: 12m 39s\n",
      "136:\tlearn: 0.1076476\ttotal: 27m 4s\tremaining: 12m 27s\n",
      "137:\tlearn: 0.1075360\ttotal: 27m 15s\tremaining: 12m 14s\n",
      "138:\tlearn: 0.1072455\ttotal: 27m 25s\tremaining: 12m 1s\n",
      "139:\tlearn: 0.1070009\ttotal: 27m 35s\tremaining: 11m 49s\n",
      "140:\tlearn: 0.1066515\ttotal: 27m 44s\tremaining: 11m 36s\n",
      "141:\tlearn: 0.1064911\ttotal: 27m 53s\tremaining: 11m 23s\n",
      "142:\tlearn: 0.1063640\ttotal: 28m 3s\tremaining: 11m 10s\n",
      "143:\tlearn: 0.1061127\ttotal: 28m 12s\tremaining: 10m 58s\n",
      "144:\tlearn: 0.1059864\ttotal: 28m 23s\tremaining: 10m 46s\n",
      "145:\tlearn: 0.1058792\ttotal: 28m 34s\tremaining: 10m 34s\n",
      "146:\tlearn: 0.1055999\ttotal: 28m 42s\tremaining: 10m 21s\n",
      "147:\tlearn: 0.1054295\ttotal: 28m 50s\tremaining: 10m 7s\n",
      "148:\tlearn: 0.1052346\ttotal: 28m 58s\tremaining: 9m 55s\n",
      "149:\tlearn: 0.1051314\ttotal: 29m 7s\tremaining: 9m 42s\n",
      "150:\tlearn: 0.1048144\ttotal: 29m 17s\tremaining: 9m 30s\n",
      "151:\tlearn: 0.1044663\ttotal: 29m 26s\tremaining: 9m 17s\n",
      "152:\tlearn: 0.1040715\ttotal: 29m 36s\tremaining: 9m 5s\n",
      "153:\tlearn: 0.1039745\ttotal: 29m 46s\tremaining: 8m 53s\n",
      "154:\tlearn: 0.1038211\ttotal: 29m 57s\tremaining: 8m 41s\n",
      "155:\tlearn: 0.1037265\ttotal: 30m 7s\tremaining: 8m 29s\n",
      "156:\tlearn: 0.1034331\ttotal: 30m 16s\tremaining: 8m 17s\n",
      "157:\tlearn: 0.1032886\ttotal: 30m 25s\tremaining: 8m 5s\n",
      "158:\tlearn: 0.1030740\ttotal: 30m 36s\tremaining: 7m 53s\n",
      "159:\tlearn: 0.1028313\ttotal: 30m 47s\tremaining: 7m 41s\n",
      "160:\tlearn: 0.1027414\ttotal: 30m 55s\tremaining: 7m 29s\n",
      "161:\tlearn: 0.1025484\ttotal: 31m 5s\tremaining: 7m 17s\n",
      "162:\tlearn: 0.1024262\ttotal: 31m 16s\tremaining: 7m 5s\n",
      "163:\tlearn: 0.1021990\ttotal: 31m 25s\tremaining: 6m 53s\n",
      "164:\tlearn: 0.1020777\ttotal: 31m 34s\tremaining: 6m 41s\n",
      "165:\tlearn: 0.1018500\ttotal: 31m 43s\tremaining: 6m 29s\n",
      "166:\tlearn: 0.1017641\ttotal: 31m 51s\tremaining: 6m 17s\n",
      "167:\tlearn: 0.1015034\ttotal: 32m\tremaining: 6m 5s\n",
      "168:\tlearn: 0.1011878\ttotal: 32m 9s\tremaining: 5m 53s\n",
      "169:\tlearn: 0.1010381\ttotal: 32m 19s\tremaining: 5m 42s\n",
      "170:\tlearn: 0.1007747\ttotal: 32m 29s\tremaining: 5m 30s\n",
      "171:\tlearn: 0.1006621\ttotal: 32m 38s\tremaining: 5m 18s\n",
      "172:\tlearn: 0.1005423\ttotal: 32m 48s\tremaining: 5m 7s\n",
      "173:\tlearn: 0.1004042\ttotal: 33m\tremaining: 4m 55s\n",
      "174:\tlearn: 0.1003163\ttotal: 33m 10s\tremaining: 4m 44s\n",
      "175:\tlearn: 0.1002297\ttotal: 33m 20s\tremaining: 4m 32s\n",
      "176:\tlearn: 0.1001132\ttotal: 33m 28s\tremaining: 4m 21s\n",
      "177:\tlearn: 0.0999175\ttotal: 33m 37s\tremaining: 4m 9s\n",
      "178:\tlearn: 0.0996963\ttotal: 33m 46s\tremaining: 3m 57s\n",
      "179:\tlearn: 0.0995940\ttotal: 33m 56s\tremaining: 3m 46s\n",
      "180:\tlearn: 0.0993981\ttotal: 34m 5s\tremaining: 3m 34s\n",
      "181:\tlearn: 0.0993077\ttotal: 34m 18s\tremaining: 3m 23s\n",
      "182:\tlearn: 0.0989632\ttotal: 34m 30s\tremaining: 3m 12s\n",
      "183:\tlearn: 0.0987140\ttotal: 34m 40s\tremaining: 3m\n",
      "184:\tlearn: 0.0986318\ttotal: 34m 49s\tremaining: 2m 49s\n",
      "185:\tlearn: 0.0984910\ttotal: 35m\tremaining: 2m 38s\n",
      "186:\tlearn: 0.0983898\ttotal: 35m 9s\tremaining: 2m 26s\n",
      "187:\tlearn: 0.0982025\ttotal: 35m 17s\tremaining: 2m 15s\n",
      "188:\tlearn: 0.0981077\ttotal: 35m 27s\tremaining: 2m 3s\n",
      "189:\tlearn: 0.0979443\ttotal: 35m 35s\tremaining: 1m 52s\n",
      "190:\tlearn: 0.0977126\ttotal: 35m 44s\tremaining: 1m 41s\n",
      "191:\tlearn: 0.0976303\ttotal: 35m 54s\tremaining: 1m 29s\n",
      "192:\tlearn: 0.0975199\ttotal: 36m 2s\tremaining: 1m 18s\n",
      "193:\tlearn: 0.0972438\ttotal: 36m 11s\tremaining: 1m 7s\n",
      "194:\tlearn: 0.0971208\ttotal: 36m 19s\tremaining: 55.9s\n",
      "195:\tlearn: 0.0969873\ttotal: 36m 27s\tremaining: 44.6s\n",
      "196:\tlearn: 0.0969125\ttotal: 36m 35s\tremaining: 33.4s\n",
      "197:\tlearn: 0.0968333\ttotal: 36m 43s\tremaining: 22.3s\n",
      "198:\tlearn: 0.0965402\ttotal: 36m 51s\tremaining: 11.1s\n",
      "199:\tlearn: 0.0963937\ttotal: 37m 1s\tremaining: 0us\n",
      "Точность предсказаний: 0.956\n",
      "-------------------------\n",
      "F1-мера 0.748\n",
      "-------------------------\n",
      "Матрица ошибок:\n",
      " [[0.99137027 0.00862973]\n",
      " [0.35742972 0.64257028]]\n"
     ]
    }
   ],
   "source": [
    "#Время исполнения - около 40 минут.\n",
    "\n",
    "model_cbc_0 = CatBoostClassifier(random_state=SEED, iterations=200, depth=8, custom_metric='F1')\n",
    "model_cbc_0.fit(features_train_0, target_train_0)\n",
    "prediction_cbc_valid_0 = model_cbc_0.predict(features_valid_0)\n",
    "show_me_quality_please(target_valid_0, prediction_cbc_valid_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель CatBoost не достигла необходимого результата."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_dtc = DecisionTreeClassifier()\n",
    "#params_dtc = {'max_depth': [35]} #Сократил для ускорения работы, подбор проходил на более широком диапазоне.\n",
    "\n",
    "#grid_dtc = GridSearchCV(model_dtc, params_dtc, cv=3)\n",
    "#grid_dtc.fit(features_train, target_train)\n",
    "#print(grid_dtc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность предсказаний: 0.947\n",
      "-------------------------\n",
      "F1-мера 0.689\n",
      "-------------------------\n",
      "Матрица ошибок:\n",
      " [[0.98958843 0.01041157]\n",
      " [0.42632067 0.57367933]]\n"
     ]
    }
   ],
   "source": [
    "model_dtc_0 = DecisionTreeClassifier(random_state=SEED, max_depth=35)\n",
    "model_dtc_0.fit(features_train_0, target_train_0)\n",
    "prediction_dtc_valid_0 = model_dtc_0.predict(features_valid_0)\n",
    "show_me_quality_please(target_valid_0, prediction_dtc_valid_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель решающего дерева не достигла треуемого качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Анализ моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуемый порог F1-меры достигла модель логистической регрессии. Проверим модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность предсказаний: 0.95\n",
      "-------------------------\n",
      "F1-мера 0.765\n",
      "-------------------------\n",
      "Матрица ошибок:\n",
      " [[0.96568953 0.03431047]\n",
      " [0.19215323 0.80784677]]\n"
     ]
    }
   ],
   "source": [
    "prediction_lr_test_0 = model_lr.predict(features_test_0)\n",
    "show_me_quality_please(target_test_0, prediction_lr_test_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель успешно ведёт себя на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе работы с текстами построили модели различных типов для классификации сообщений. Наибольшую эффективность показала модель логистической регрессии: F1-мера 0.765 на тестовой выборке. Модель CatBoost имеет второе качество, но она не достигла требуемого порога, также время и затраты на работу модели не позволяют утверждать о её эффективности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
